import * as tf from '@tensorflow/tfjs';
import * as mobilenet from '@tensorflow-models/mobilenet';
import Tesseract from 'tesseract.js';
import { RecognitionRule } from '../types';

let model: mobilenet.MobileNet | null = null;

// 1. åŠ è½½æ¨¡å‹
export async function loadModels() {
  console.log("ğŸš€ æ­£åœ¨åŠ è½½ AI æ¨¡å‹...");
  try {
    await tf.ready();
    // åŠ è½½ MobileNet (ç”¨äºç‰©ä½“è¯†åˆ«)
    model = await mobilenet.load({ version: 2, alpha: 1.0 });
    console.log("âœ… MobileNet æ¨¡å‹åŠ è½½å®Œæ¯•");
  } catch (e) {
    console.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥:", e);
  }
}

// è¾…åŠ©ï¼šå›¾ç‰‡è½¬å…ƒç´ 
async function createImageElement(src: string): Promise<HTMLImageElement> {
  return new Promise((resolve, reject) => {
    const img = new Image();
    img.crossOrigin = 'anonymous';
    img.src = src;
    img.onload = () => resolve(img);
    img.onerror = (e) => reject(e);
  });
}

// 2. æå–ç‰¹å¾ (ç”¨äºç›¸ä¼¼åº¦æ¯”å¯¹)
export async function extractEmbedding(image: HTMLImageElement): Promise<number[] | null> {
  if (!model) await loadModels();
  if (!model) return null;
  try {
    // è·å–ä¸­é—´å±‚ç‰¹å¾
    const embedding = model.infer(image, true); 
    const data = await embedding.data();
    embedding.dispose();
    return Array.from(data);
  } catch (e) {
    console.error("ç‰¹å¾æå–å¤±è´¥", e);
    return null;
  }
}

// è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
function cosineSimilarity(a: number[], b: number[]) {
  let dotProduct = 0;
  let mA = 0;
  let mB = 0;
  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i];
    mA += a[i] * a[i];
    mB += b[i] * b[i];
  }
  return dotProduct / (Math.sqrt(mA) * Math.sqrt(mB));
}

// 3. æ ¸å¿ƒåˆ†æé€»è¾‘ (åŒ…å« OCR å’Œ ç‰©ä½“è¯†åˆ«)
export async function analyzeImageLocal(base64Image: string, rules: RecognitionRule[]): Promise<string | null> {
  const imgElement = await createImageElement(base64Image);
  
  // --- A. å…ˆè·‘ OCR (æ–‡å­—è¯†åˆ«) ---
  // å¦‚æœæœ‰ OCR ç±»å‹çš„è§„åˆ™ï¼Œæ‰å»è·‘ Tesseract (å› ä¸ºå®ƒæ¯”è¾ƒæ…¢)
  const hasOCRRule = rules.some(r => r.targetType === 'ocr');
  if (hasOCRRule) {
    console.log("ğŸ“– æ­£åœ¨è¿›è¡Œ OCR æ–‡å­—è¯†åˆ«...");
    const { data: { text } } = await Tesseract.recognize(base64Image, 'eng'); // é»˜è®¤è¯†åˆ«è‹±æ–‡æ•°å­—
    console.log("OCR ç»“æœ:", text);
    
    // åŒ¹é…æ–‡å­—è§„åˆ™
    const ocrMatch = rules.find(r => 
      r.targetType === 'ocr' && 
      text.toLowerCase().includes(r.targetValue.toLowerCase())
    );
    if (ocrMatch) return ocrMatch.id;
  }

  // --- B. å†è·‘ MobileNet (ç‰©ä½“è¯†åˆ«) ---
  if (!model) await loadModels();
  if (model) {
    console.log("ğŸ” æ­£åœ¨è¿›è¡Œç‰©ä½“åˆ†æ...");
    
    // 1. è·å–åˆ†ç±»æ ‡ç­¾ (Top 3)
    const predictions = await model.classify(imgElement);
    console.log("AI çœ‹åˆ°çš„ç‰©ä½“:", predictions); // ğŸ‘ˆ åœ¨æ§åˆ¶å°çœ‹è¿™ä¸ªå¾ˆé‡è¦ï¼

    // 2. åŒ¹é…ç‰©ä½“è§„åˆ™ (Image Type)
    const imageMatch = rules.find(r => {
      if (r.targetType !== 'image') return false;
      // æ£€æŸ¥ AI é¢„æµ‹çš„ className æ˜¯å¦åŒ…å«ä½ å¡«å†™çš„å•è¯
      return predictions.some(p => p.className.toLowerCase().includes(r.targetValue.toLowerCase()));
    });
    if (imageMatch) return imageMatch.id;

    // 3. åŒ¹é…ç›¸ä¼¼åº¦è§„åˆ™ (Similarity Type)
    const embedding = await extractEmbedding(imgElement);
    if (embedding) {
      // æ‰¾åˆ°æ‰€æœ‰ç›¸ä¼¼åº¦ç±»å‹çš„è§„åˆ™
      const simRules = rules.filter(r => r.targetType === 'similarity' && r.embedding);
      
      for (const rule of simRules) {
        if (rule.embedding) {
          const sim = cosineSimilarity(embedding, rule.embedding);
          console.log(`ä¸è§„åˆ™ [${rule.name}] çš„ç›¸ä¼¼åº¦:`, sim);
          
          // è¿™é‡Œçš„é˜ˆå€¼ (threshold) å¯ä»¥åœ¨åå°è®¾ç½®ï¼Œé»˜è®¤å»ºè®® 0.8 ä»¥ä¸Š
          const threshold = rule.similarityThreshold || 0.85;
          if (sim > threshold) {
            return rule.id;
          }
        }
      }
    }
  }

  return null;
}
